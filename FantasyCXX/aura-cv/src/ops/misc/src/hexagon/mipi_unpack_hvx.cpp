#include "aura/ops/misc/mipi.hpp"
#include "mipi_impl.hpp"
#include "misc_comm.hpp"
#include "aura/runtime/worker_pool.h"
#include "aura/runtime/logger.h"

namespace aura
{

static const DT_U8 ctrl_perm_u8[] __attribute__((aligned(128))) =
{
    0x00,0x00,0x00,0x00,0x01,0x02,0x01,0x09,0x02,0x03,0x04,0x06,0x02,0x10,0x13,0x16,
    0x05,0x05,0x06,0x05,0x08,0x0C,0x0C,0x0C,0x05,0x06,0x21,0x21,0x26,0x2F,0x2C,0x2A,
    0x0A,0x08,0x0B,0x0A,0x0D,0x09,0x0A,0x11,0x10,0x10,0x18,0x18,0x19,0x1A,0x19,0x19,
    0x0A,0x0B,0x0C,0x0E,0x42,0x40,0x43,0x46,0x4D,0x4D,0x5E,0x5D,0x58,0x54,0x54,0x54,
    0x15,0x16,0x11,0x11,0x16,0x17,0x14,0x12,0x1A,0x18,0x13,0x12,0x15,0x21,0x22,0x21,
    0x20,0x20,0x20,0x20,0x31,0x32,0x31,0x39,0x32,0x33,0x34,0x36,0x32,0x30,0x33,0x36,
    0x15,0x15,0x16,0x15,0x18,0x1C,0x1C,0x0C,0x05,0x06,0x01,0x01,0x06,0x0F,0x0C,0x0A,
    0x1A,0x18,0x1B,0x1A,0x3D,0x39,0x3A,0x31,0x30,0x30,0x28,0x28,0x29,0x2A,0x29,0x29,

    0x2A,0x2B,0x2C,0x2E,0x22,0x20,0x23,0x26,0x2D,0x2D,0x2E,0x2D,0x28,0x24,0x24,0x24,
    0x35,0x36,0x31,0x31,0x26,0x27,0x24,0x22,0x2A,0x28,0x43,0x42,0x45,0x41,0x42,0x41,
    0x40,0x40,0x40,0x40,0x41,0x42,0x41,0x69,0x62,0x63,0x64,0x66,0x62,0x70,0x73,0x76,
    0x65,0x65,0x66,0x65,0x68,0x6C,0x6C,0x6C,0x65,0x66,0x61,0x61,0x66,0x6F,0x6C,0x6A,
    0x2A,0x28,0x2B,0x2A,0x2D,0x29,0x2A,0x31,0x30,0x30,0x38,0x38,0x39,0x1A,0x19,0x19,
    0x0A,0x0B,0x0C,0x0E,0x02,0x00,0x03,0x06,0x0D,0x0D,0x1E,0x1D,0x18,0x14,0x14,0x14,
    0x35,0x36,0x31,0x31,0x36,0x37,0x34,0x72,0x7A,0x78,0x73,0x72,0x75,0x61,0x62,0x61,
    0x60,0x60,0x60,0x60,0x51,0x52,0x51,0x59,0x52,0x53,0x54,0x56,0x52,0x50,0x53,0x56,

    0x55,0x55,0x56,0x55,0x58,0x5C,0x5C,0x4C,0x45,0x46,0x41,0x41,0x46,0x4F,0x4C,0x4A,
    0x5A,0x58,0x5B,0x5A,0x5D,0x59,0x5A,0x51,0x50,0x50,0x48,0x48,0x49,0x4A,0x49,0x49,
    0x6A,0x6B,0x6C,0x6E,0x62,0x60,0x63,0x46,0x4D,0x4D,0x4E,0x4D,0x48,0x44,0x44,0x44,
    0x55,0x56,0x51,0x51,0x06,0x07,0x04,0x02,0x0A,0x08,0x03,0x02,0x05,0x01,0x02,0x01,
    0x00,0x00,0x00,0x00,0x01,0x02,0x01,0x09,0x02,0x03,0x04,0x06,0x02,0x50,0x53,0x56,
    0x45,0x45,0x46,0x45,0x48,0x4C,0x4C,0x4C,0x45,0x46,0x61,0x61,0x66,0x6F,0x6C,0x6A,
    0x4A,0x48,0x4B,0x4A,0x4D,0x49,0x4A,0x51,0x50,0x50,0x58,0x58,0x59,0x5A,0x59,0x59,
    0x4A,0x4B,0x4C,0x4E,0x42,0x40,0x43,0x46,0x4D,0x4D,0x5E,0x5D,0x58,0x54,0x54,0x54,

    0x55,0x56,0x51,0x51,0x56,0x57,0x54,0x52,0x5A,0x58,0x53,0x52,0x55,0x61,0x62,0x61,
    0x60,0x60,0x60,0x60,0x71,0x72,0x71,0x79,0x72,0x73,0x34,0x36,0x32,0x30,0x33,0x36,
    0x15,0x15,0x16,0x15,0x18,0x1C,0x1C,0x0C,0x05,0x06,0x01,0x01,0x06,0x0F,0x0C,0x0A,
    0x1A,0x18,0x1B,0x1A,0x3D,0x39,0x3A,0x31,0x30,0x30,0x28,0x28,0x29,0x2A,0x29,0x29,
    0x6A,0x6B,0x6C,0x6E,0x62,0x60,0x63,0x66,0x6D,0x6D,0x6E,0x6D,0x68,0x64,0x64,0x64,
    0x75,0x76,0x71,0x71,0x66,0x67,0x64,0x62,0x6A,0x68,0x43,0x42,0x45,0x41,0x42,0x41,
    0x40,0x40,0x40,0x40,0x41,0x42,0x41,0x29,0x22,0x23,0x24,0x26,0x22,0x30,0x33,0x36,
    0x25,0x25,0x26,0x25,0x28,0x2C,0x2C,0x2C,0x25,0x26,0x21,0x21,0x26,0x2F,0x2C,0x2A,

    0x2A,0x28,0x2B,0x2A,0x2D,0x29,0x2A,0x31,0x30,0x30,0x38,0x38,0x39,0x1A,0x19,0x19,
    0x0A,0x0B,0x0C,0x0E,0x02,0x00,0x03,0x06,0x0D,0x0D,0x1E,0x1D,0x18,0x14,0x14,0x14,
    0x35,0x36,0x31,0x31,0x36,0x37,0x34,0x32,0x3A,0x38,0x33,0x32,0x35,0x21,0x22,0x21,
    0x20,0x20,0x20,0x20,0x11,0x12,0x11,0x19,0x12,0x13,0x14,0x16,0x12,0x10,0x13,0x16,
    0x55,0x55,0x56,0x55,0x58,0x5C,0x5C,0x4C,0x45,0x46,0x41,0x41,0x46,0x0F,0x0C,0x0A,
    0x1A,0x18,0x1B,0x1A,0x1D,0x19,0x1A,0x11,0x10,0x10,0x08,0x08,0x09,0x0A,0x09,0x09,
    0x2A,0x2B,0x2C,0x2E,0x22,0x20,0x23,0x06,0x0D,0x0D,0x0E,0x0D,0x08,0x04,0x04,0x04,
    0x15,0x16,0x11,0x11,0x06,0x07,0x04,0x02,0x0A,0x08,0x03,0x02,0x05,0x01,0x02,0x01,

    //Q registers for muxing
    0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
    0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0x7f,0x7f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,
    0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,
    0x1f,0x1f,0x1f,0x1f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,
    0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x07,0x03,0x03,0x03,
    0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,
    0x03,0x03,0x03,0x03,0x01,0x01,0x01,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
    0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
};

static const DT_U8 ctrl_perm_u16[] __attribute__((aligned(128))) =
{
    0x00,0x00,0x00,0x00,0x01,0x02,0x01,0x09,0x02,0x03,0x04,0x06,0x02,0x10,0x13,0x16,
    0x05,0x05,0x06,0x05,0x08,0x0C,0x0C,0x0C,0x05,0x06,0x21,0x21,0x26,0x2F,0x2C,0x2A,
    0x0A,0x08,0x0B,0x0A,0x0D,0x09,0x0A,0x11,0x10,0x10,0x18,0x18,0x19,0x1A,0x19,0x19,
    0x0A,0x0B,0x0C,0x0E,0x42,0x40,0x43,0x46,0x4D,0x4D,0x5E,0x5D,0x58,0x54,0x54,0x54,
    0x15,0x16,0x11,0x11,0x16,0x17,0x14,0x12,0x1A,0x18,0x13,0x12,0x15,0x21,0x22,0x21,
    0x20,0x20,0x20,0x20,0x31,0x32,0x31,0x39,0x32,0x33,0x34,0x36,0x32,0x30,0x33,0x36,
    0x15,0x15,0x16,0x15,0x18,0x1C,0x1C,0x0C,0x05,0x06,0x01,0x01,0x06,0x0F,0x0C,0x0A,
    0x1A,0x18,0x1B,0x1A,0x3D,0x39,0x3A,0x31,0x30,0x30,0x28,0x28,0x29,0x2A,0x29,0x29,

    0x04,0x04,0x04,0x04,0x08,0x09,0x0A,0x0A,0x05,0x04,0x06,0x06,0x16,0x16,0x14,0x15,
    0x0A,0x0A,0x09,0x08,0x0C,0x0C,0x0C,0x0C,0x20,0x21,0x22,0x22,0x29,0x28,0x2A,0x2A,
    0x0A,0x0A,0x08,0x09,0x12,0x12,0x11,0x10,0x1C,0x1C,0x1C,0x1C,0x18,0x19,0x1A,0x1A,
    0x45,0x44,0x46,0x46,0x46,0x46,0x44,0x45,0x5A,0x5A,0x59,0x58,0x54,0x54,0x54,0x54,
    0x10,0x11,0x12,0x12,0x11,0x10,0x12,0x12,0x12,0x12,0x10,0x11,0x22,0x22,0x21,0x20,
    0x34,0x34,0x34,0x34,0x38,0x39,0x3A,0x3A,0x35,0x34,0x36,0x36,0x36,0x36,0x34,0x35,
    0x1A,0x1A,0x19,0x18,0x0C,0x0C,0x0C,0x0C,0x00,0x01,0x02,0x02,0x09,0x08,0x0A,0x0A,
    0x3A,0x3A,0x38,0x39,0x32,0x32,0x31,0x30,0x2C,0x2C,0x2C,0x2C,0x28,0x29,0x2A,0x2A,

    0x2A,0x2B,0x2C,0x2E,0x22,0x20,0x23,0x26,0x2D,0x2D,0x2E,0x2D,0x28,0x24,0x24,0x24,
    0x35,0x36,0x31,0x31,0x26,0x27,0x24,0x22,0x2A,0x28,0x43,0x42,0x45,0x41,0x42,0x41,
    0x40,0x40,0x40,0x40,0x41,0x42,0x41,0x69,0x62,0x63,0x64,0x66,0x62,0x70,0x73,0x76,
    0x65,0x65,0x66,0x65,0x68,0x6C,0x6C,0x6C,0x65,0x66,0x61,0x61,0x66,0x6F,0x6C,0x6A,
    0x2A,0x28,0x2B,0x2A,0x2D,0x29,0x2A,0x31,0x30,0x30,0x38,0x38,0x39,0x1A,0x19,0x19,
    0x0A,0x0B,0x0C,0x0E,0x02,0x00,0x03,0x06,0x0D,0x0D,0x1E,0x1D,0x18,0x14,0x14,0x14,
    0x35,0x36,0x31,0x31,0x36,0x37,0x34,0x72,0x7A,0x78,0x73,0x72,0x75,0x61,0x62,0x61,
    0x60,0x60,0x60,0x60,0x51,0x52,0x51,0x59,0x52,0x53,0x54,0x56,0x52,0x50,0x53,0x56,

    0x25,0x24,0x26,0x26,0x26,0x26,0x24,0x25,0x2A,0x2A,0x29,0x28,0x24,0x24,0x24,0x24,
    0x20,0x21,0x22,0x22,0x21,0x20,0x22,0x22,0x42,0x42,0x40,0x41,0x42,0x42,0x41,0x40,
    0x44,0x44,0x44,0x44,0x68,0x69,0x6A,0x6A,0x65,0x64,0x66,0x66,0x76,0x76,0x74,0x75,
    0x6A,0x6A,0x69,0x68,0x6C,0x6C,0x6C,0x6C,0x60,0x61,0x62,0x62,0x69,0x68,0x6A,0x6A,
    0x2A,0x2A,0x28,0x29,0x32,0x32,0x31,0x30,0x3C,0x3C,0x3C,0x3C,0x18,0x19,0x1A,0x1A,
    0x05,0x04,0x06,0x06,0x06,0x06,0x04,0x05,0x1A,0x1A,0x19,0x18,0x14,0x14,0x14,0x14,
    0x30,0x31,0x32,0x32,0x71,0x70,0x72,0x72,0x72,0x72,0x70,0x71,0x62,0x62,0x61,0x60,
    0x54,0x54,0x54,0x54,0x58,0x59,0x5A,0x5A,0x55,0x54,0x56,0x56,0x56,0x56,0x54,0x55,

    0x55,0x55,0x56,0x55,0x58,0x5C,0x5C,0x4C,0x45,0x46,0x41,0x41,0x46,0x4F,0x4C,0x4A,
    0x5A,0x58,0x5B,0x5A,0x5D,0x59,0x5A,0x51,0x50,0x50,0x48,0x48,0x49,0x4A,0x49,0x49,
    0x6A,0x6B,0x6C,0x6E,0x62,0x60,0x63,0x46,0x4D,0x4D,0x4E,0x4D,0x48,0x44,0x44,0x44,
    0x55,0x56,0x51,0x51,0x06,0x07,0x04,0x02,0x0A,0x08,0x03,0x02,0x05,0x01,0x02,0x01,
    0x00,0x00,0x00,0x00,0x01,0x02,0x01,0x09,0x02,0x03,0x04,0x06,0x02,0x50,0x53,0x56,
    0x45,0x45,0x46,0x45,0x48,0x4C,0x4C,0x4C,0x45,0x46,0x61,0x61,0x66,0x6F,0x6C,0x6A,
    0x4A,0x48,0x4B,0x4A,0x4D,0x49,0x4A,0x51,0x50,0x50,0x58,0x58,0x59,0x5A,0x59,0x59,
    0x4A,0x4B,0x4C,0x4E,0x42,0x40,0x43,0x46,0x4D,0x4D,0x5E,0x5D,0x58,0x54,0x54,0x54,

    0x5A,0x5A,0x59,0x58,0x4C,0x4C,0x4C,0x4C,0x40,0x41,0x42,0x42,0x49,0x48,0x4A,0x4A,
    0x5A,0x5A,0x58,0x59,0x52,0x52,0x51,0x50,0x4C,0x4C,0x4C,0x4C,0x48,0x49,0x4A,0x4A,
    0x65,0x64,0x66,0x66,0x46,0x46,0x44,0x45,0x4A,0x4A,0x49,0x48,0x44,0x44,0x44,0x44,
    0x00,0x01,0x02,0x02,0x01,0x00,0x02,0x02,0x02,0x02,0x00,0x01,0x02,0x02,0x01,0x00,
    0x04,0x04,0x04,0x04,0x08,0x09,0x0A,0x0A,0x05,0x04,0x06,0x06,0x56,0x56,0x54,0x55,
    0x4A,0x4A,0x49,0x48,0x4C,0x4C,0x4C,0x4C,0x60,0x61,0x62,0x62,0x69,0x68,0x6A,0x6A,
    0x4A,0x4A,0x48,0x49,0x52,0x52,0x51,0x50,0x5C,0x5C,0x5C,0x5C,0x58,0x59,0x5A,0x5A,
    0x45,0x44,0x46,0x46,0x46,0x46,0x44,0x45,0x5A,0x5A,0x59,0x58,0x54,0x54,0x54,0x54,

    0x55,0x56,0x51,0x51,0x56,0x57,0x54,0x52,0x5A,0x58,0x53,0x52,0x55,0x61,0x62,0x61,
    0x60,0x60,0x60,0x60,0x71,0x72,0x71,0x79,0x72,0x73,0x34,0x36,0x32,0x30,0x33,0x36,
    0x15,0x15,0x16,0x15,0x18,0x1C,0x1C,0x0C,0x05,0x06,0x01,0x01,0x06,0x0F,0x0C,0x0A,
    0x1A,0x18,0x1B,0x1A,0x3D,0x39,0x3A,0x31,0x30,0x30,0x28,0x28,0x29,0x2A,0x29,0x29,
    0x6A,0x6B,0x6C,0x6E,0x62,0x60,0x63,0x66,0x6D,0x6D,0x6E,0x6D,0x68,0x64,0x64,0x64,
    0x75,0x76,0x71,0x71,0x66,0x67,0x64,0x62,0x6A,0x68,0x43,0x42,0x45,0x41,0x42,0x41,
    0x40,0x40,0x40,0x40,0x41,0x42,0x41,0x29,0x22,0x23,0x24,0x26,0x22,0x30,0x33,0x36,
    0x25,0x25,0x26,0x25,0x28,0x2C,0x2C,0x2C,0x25,0x26,0x21,0x21,0x26,0x2F,0x2C,0x2A,

    0x50,0x51,0x52,0x52,0x51,0x50,0x52,0x52,0x52,0x52,0x50,0x51,0x62,0x62,0x61,0x60,
    0x74,0x74,0x74,0x74,0x78,0x79,0x7A,0x7A,0x35,0x34,0x36,0x36,0x36,0x36,0x34,0x35,
    0x1A,0x1A,0x19,0x18,0x0C,0x0C,0x0C,0x0C,0x00,0x01,0x02,0x02,0x09,0x08,0x0A,0x0A,
    0x3A,0x3A,0x38,0x39,0x32,0x32,0x31,0x30,0x2C,0x2C,0x2C,0x2C,0x28,0x29,0x2A,0x2A,
    0x65,0x64,0x66,0x66,0x66,0x66,0x64,0x65,0x6A,0x6A,0x69,0x68,0x64,0x64,0x64,0x64,
    0x60,0x61,0x62,0x62,0x61,0x60,0x62,0x62,0x42,0x42,0x40,0x41,0x42,0x42,0x41,0x40,
    0x44,0x44,0x44,0x44,0x28,0x29,0x2A,0x2A,0x25,0x24,0x26,0x26,0x36,0x36,0x34,0x35,
    0x2A,0x2A,0x29,0x28,0x2C,0x2C,0x2C,0x2C,0x20,0x21,0x22,0x22,0x29,0x28,0x2A,0x2A,

    0x2A,0x28,0x2B,0x2A,0x2D,0x29,0x2A,0x31,0x30,0x30,0x38,0x38,0x39,0x1A,0x19,0x19,
    0x0A,0x0B,0x0C,0x0E,0x02,0x00,0x03,0x06,0x0D,0x0D,0x1E,0x1D,0x18,0x14,0x14,0x14,
    0x35,0x36,0x31,0x31,0x36,0x37,0x34,0x32,0x3A,0x38,0x33,0x32,0x35,0x21,0x22,0x21,
    0x20,0x20,0x20,0x20,0x11,0x12,0x11,0x19,0x12,0x13,0x14,0x16,0x12,0x10,0x13,0x16,
    0x55,0x55,0x56,0x55,0x58,0x5C,0x5C,0x4C,0x45,0x46,0x41,0x41,0x46,0x0F,0x0C,0x0A,
    0x1A,0x18,0x1B,0x1A,0x1D,0x19,0x1A,0x11,0x10,0x10,0x08,0x08,0x09,0x0A,0x09,0x09,
    0x2A,0x2B,0x2C,0x2E,0x22,0x20,0x23,0x06,0x0D,0x0D,0x0E,0x0D,0x08,0x04,0x04,0x04,
    0x15,0x16,0x11,0x11,0x06,0x07,0x04,0x02,0x0A,0x08,0x03,0x02,0x05,0x01,0x02,0x01,

    0x2A,0x2A,0x28,0x29,0x32,0x32,0x31,0x30,0x3C,0x3C,0x3C,0x3C,0x18,0x19,0x1A,0x1A,
    0x05,0x04,0x06,0x06,0x06,0x06,0x04,0x05,0x1A,0x1A,0x19,0x18,0x14,0x14,0x14,0x14,
    0x30,0x31,0x32,0x32,0x31,0x30,0x32,0x32,0x32,0x32,0x30,0x31,0x22,0x22,0x21,0x20,
    0x14,0x14,0x14,0x14,0x18,0x19,0x1A,0x1A,0x15,0x14,0x16,0x16,0x16,0x16,0x14,0x15,
    0x5A,0x5A,0x59,0x58,0x4C,0x4C,0x4C,0x4C,0x40,0x41,0x42,0x42,0x09,0x08,0x0A,0x0A,
    0x1A,0x1A,0x18,0x19,0x12,0x12,0x11,0x10,0x0C,0x0C,0x0C,0x0C,0x08,0x09,0x0A,0x0A,
    0x25,0x24,0x26,0x26,0x06,0x06,0x04,0x05,0x0A,0x0A,0x09,0x08,0x04,0x04,0x04,0x04,
    0x00,0x01,0x02,0x02,0x01,0x00,0x02,0x02,0x02,0x02,0x00,0x01,0x02,0x02,0x01,0x00,

    //Q registers for muxing
    0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
    0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0x7f,0x7f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,
    0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,0x3f,
    0x1f,0x1f,0x1f,0x1f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,
    0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x0f,0x07,0x03,0x03,0x03,
    0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,0x03,
    0x03,0x03,0x03,0x03,0x01,0x01,0x01,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
    0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
};

AURA_ALWAYS_INLINE DT_VOID MipiUnpackRowCoreU8(HVX_Vector &vu8_src0, HVX_Vector &vu8_src1, HVX_Vector &vu8_src2, HVX_Vector &vu8_src3, HVX_Vector &vu8_src4,
                                               HVX_Vector &vu8_dst0, HVX_Vector &vu8_dst1, HVX_Vector &vu8_dst2, HVX_Vector &vu8_dst3)
{
    HVX_Vector *ctrl_data      = (HVX_Vector *)ctrl_perm_u8;
    HVX_Vector vu8_ctrl_msb_a  = ctrl_data[0];
    HVX_Vector vu8_ctrl_msb_ab = ctrl_data[1];
    HVX_Vector vu8_ctrl_msb_bc = ctrl_data[2];
    HVX_Vector vu8_ctrl_msb_cd = ctrl_data[3];
    HVX_Vector vu8_ctrl_msb_e  = ctrl_data[4];
    HVX_Vector qu8_pred        = ctrl_data[5];

    DT_S32 pos0 = 0x1010101;
    DT_S32 pos1 = pos0 + pos0;
    DT_S32 pos2 = pos1 + pos1;
    DT_S32 pos3 = pos2 + pos2;
    DT_S32 pos4 = pos3 + pos3;
    DT_S32 pos5 = pos4 + pos4;
    DT_S32 pos6 = pos5 + pos5;

    HVX_Vector vu8_perm_msb0, vu8_perm_msb1, vu8_perm_msb2, vu8_perm_msb3, vu8_perm_msb4;
    HVX_VectorPred qu8_pred0, qu8_pred2, qu8_pred4, qu8_pred6;

    vu8_perm_msb0 = Q6_V_vrdelta_VV(vu8_src0, vu8_ctrl_msb_a);
    vu8_perm_msb1 = Q6_V_vrdelta_VV(vu8_src1, vu8_ctrl_msb_ab);
    vu8_perm_msb2 = Q6_V_vrdelta_VV(vu8_src2, vu8_ctrl_msb_bc);
    vu8_perm_msb3 = Q6_V_vrdelta_VV(vu8_src3, vu8_ctrl_msb_cd);
    vu8_perm_msb4 = Q6_V_vrdelta_VV(vu8_src4, vu8_ctrl_msb_e);

    qu8_pred0 = Q6_Q_vand_VR(qu8_pred, pos0);
    qu8_pred2 = Q6_Q_vand_VR(qu8_pred, pos2);
    qu8_pred4 = Q6_Q_vand_VR(qu8_pred, pos4);
    qu8_pred6 = Q6_Q_vand_VR(qu8_pred, pos6);

    vu8_dst0 = Q6_V_vmux_QVV(qu8_pred0, vu8_perm_msb0, vu8_perm_msb1);
    vu8_dst1 = Q6_V_vmux_QVV(qu8_pred2, vu8_perm_msb1, vu8_perm_msb2);
    vu8_dst2 = Q6_V_vmux_QVV(qu8_pred4, vu8_perm_msb2, vu8_perm_msb3);
    vu8_dst3 = Q6_V_vmux_QVV(qu8_pred6, vu8_perm_msb3, vu8_perm_msb4);
}

template <typename Dt, typename std::enable_if<std::is_same<Dt, DT_U8>::value>::type* = DT_NULL>
static DT_VOID MipiUnPackRow(const DT_U8 *src, Dt *dst, DT_S32 width)
{
    DT_S32 width_algin = width & (-4 * AURA_HVLEN);

    HVX_Vector vu8_src0, vu8_src1, vu8_src2, vu8_src3, vu8_src4;
    HVX_Vector vu8_dst0, vu8_dst1, vu8_dst2, vu8_dst3;
    
    for (DT_S32 x = 0; x < width_algin; x += 4 * AURA_HVLEN)
    {
        vload(src, vu8_src0);
        vload(src + AURA_HVLEN, vu8_src1);
        vload(src + AURA_HVLEN * 2, vu8_src2);
        vload(src + AURA_HVLEN * 3, vu8_src3);
        vload(src + AURA_HVLEN * 4, vu8_src4);

        MipiUnpackRowCoreU8(vu8_src0, vu8_src1, vu8_src2, vu8_src3, vu8_src4, vu8_dst0, vu8_dst1, vu8_dst2, vu8_dst3);

        vstore(dst                 , vu8_dst0);
        vstore(dst + AURA_HVLEN    , vu8_dst1);
        vstore(dst + AURA_HVLEN * 2, vu8_dst2);
        vstore(dst + AURA_HVLEN * 3, vu8_dst3);
        
        src += 5 * AURA_HVLEN;
        dst += (AURA_HVLEN << 2);
    }
    // tail
    if (width - width_algin)
    {
        DT_S32 length = ((width - width_algin) >> 2) * 5;
        dst = dst + (width - width_algin) - (AURA_HVLEN << 2);

        vload(src + length - AURA_HVLEN * 5, vu8_src0);
        vload(src + length - AURA_HVLEN * 4, vu8_src1);
        vload(src + length - AURA_HVLEN * 3, vu8_src2);
        vload(src + length - AURA_HVLEN * 2, vu8_src3);
        vload(src + length - AURA_HVLEN, vu8_src4);

        MipiUnpackRowCoreU8(vu8_src0, vu8_src1, vu8_src2, vu8_src3, vu8_src4, vu8_dst0, vu8_dst1, vu8_dst2, vu8_dst3);

        vstore(dst                 , vu8_dst0);
        vstore(dst + AURA_HVLEN    , vu8_dst1);
        vstore(dst + AURA_HVLEN * 2, vu8_dst2);
        vstore(dst + AURA_HVLEN * 3, vu8_dst3);
    }
}

AURA_ALWAYS_INLINE DT_VOID MipiUnPackRowCoreU16(HVX_Vector &vu8_src0, HVX_Vector &vu8_src1, HVX_Vector &vu8_src2, HVX_Vector &vu8_src3, HVX_Vector &vu8_src4,
                                                HVX_VectorPair &wu16_dst0, HVX_VectorPair &wu16_dst1, HVX_VectorPair &wu16_dst2, HVX_VectorPair &wu16_dst3)
{
    HVX_Vector *ctrl_data = (HVX_Vector *)ctrl_perm_u16;

    HVX_Vector vu8_ctrl_msb_a  = ctrl_data[0];
    HVX_Vector vu8_ctrl_lsb_a  = ctrl_data[1];
    HVX_Vector vu8_ctrl_msb_ab = ctrl_data[2];
    HVX_Vector vu8_ctrl_lsb_ab = ctrl_data[3];
    HVX_Vector vu8_ctrl_msb_bc = ctrl_data[4];
    HVX_Vector vu8_ctrl_lsb_bc = ctrl_data[5];
    HVX_Vector vu8_ctrl_msb_cd = ctrl_data[6];
    HVX_Vector vu8_ctrl_lsb_cd = ctrl_data[7];
    HVX_Vector vu8_ctrl_msb_e  = ctrl_data[8];
    HVX_Vector vu8_ctrl_lsb_e  = ctrl_data[9];
    HVX_Vector qu8_pred        = ctrl_data[10];

    DT_S32 const0401 = 0x04010401;

    HVX_Vector vu8_const_3 = Q6_V_vsplat_R(0x03030303);
    HVX_Vector vu8_shift   = Q6_V_vsplat_R(0x40000);
    HVX_Vector vu8_oddeven = Q6_V_vsplat_R(0x30003);

    HVX_VectorPred qu8_oddeven = Q6_Q_vcmp_eq_VbVb(vu8_oddeven, vu8_const_3);

    DT_S32 pos0 = 0x1010101;
    DT_S32 pos1 = pos0 + pos0;
    DT_S32 pos2 = pos1 + pos1;
    DT_S32 pos3 = pos2 + pos2;
    DT_S32 pos4 = pos3 + pos3;
    DT_S32 pos5 = pos4 + pos4;
    DT_S32 pos6 = pos5 + pos5;
    DT_S32 pos7 = pos6 + pos6;

    HVX_Vector vu8_shift04, vu8_shift26;
    HVX_VectorPair wu16_out_perm0, wu16_out_perm1, wu16_out_perm2, wu16_out_perm3;

    HVX_Vector vu8_perm_msb_0 = Q6_V_vrdelta_VV(vu8_src0, vu8_ctrl_msb_a);
    HVX_Vector vu8_perm_lsb_0 = Q6_V_vrdelta_VV(vu8_src0, vu8_ctrl_lsb_a);
    HVX_Vector vu8_perm_msb_1 = Q6_V_vrdelta_VV(vu8_src1, vu8_ctrl_msb_ab);
    HVX_Vector vu8_perm_lsb_1 = Q6_V_vrdelta_VV(vu8_src1, vu8_ctrl_lsb_ab);
    HVX_Vector vu8_perm_msb_2 = Q6_V_vrdelta_VV(vu8_src2, vu8_ctrl_msb_bc);
    HVX_Vector vu8_perm_lsb_2 = Q6_V_vrdelta_VV(vu8_src2, vu8_ctrl_lsb_bc);
    HVX_Vector vu8_perm_msb_3 = Q6_V_vrdelta_VV(vu8_src3, vu8_ctrl_msb_cd);
    HVX_Vector vu8_perm_lsb_3 = Q6_V_vrdelta_VV(vu8_src3, vu8_ctrl_lsb_cd);
    HVX_Vector vu8_perm_msb_4 = Q6_V_vrdelta_VV(vu8_src4, vu8_ctrl_msb_e);
    HVX_Vector vu8_perm_lsb_4 = Q6_V_vrdelta_VV(vu8_src4, vu8_ctrl_lsb_e);

    HVX_VectorPred qu8_pred0 = Q6_Q_vand_VR(qu8_pred, pos0);
    HVX_VectorPred qu8_pred1 = Q6_Q_vand_VR(qu8_pred, pos1);
    HVX_VectorPred qu8_pred2 = Q6_Q_vand_VR(qu8_pred, pos2);
    HVX_VectorPred qu8_pred3 = Q6_Q_vand_VR(qu8_pred, pos3);
    HVX_VectorPred qu8_pred4 = Q6_Q_vand_VR(qu8_pred, pos4);
    HVX_VectorPred qu8_pred5 = Q6_Q_vand_VR(qu8_pred, pos5);
    HVX_VectorPred qu8_pred6 = Q6_Q_vand_VR(qu8_pred, pos6);
    HVX_VectorPred qu8_pred7 = Q6_Q_vand_VR(qu8_pred, pos7);

    HVX_Vector vu8_msb_0 = Q6_V_vmux_QVV(qu8_pred0, vu8_perm_msb_0, vu8_perm_msb_1);
    HVX_Vector vu8_lsb_0 = Q6_V_vmux_QVV(qu8_pred1, vu8_perm_lsb_0, vu8_perm_lsb_1);
    HVX_Vector vu8_msb_1 = Q6_V_vmux_QVV(qu8_pred2, vu8_perm_msb_1, vu8_perm_msb_2);
    HVX_Vector vu8_lsb_1 = Q6_V_vmux_QVV(qu8_pred3, vu8_perm_lsb_1, vu8_perm_lsb_2);
    HVX_Vector vu8_msb_2 = Q6_V_vmux_QVV(qu8_pred4, vu8_perm_msb_2, vu8_perm_msb_3);
    HVX_Vector vu8_lsb_2 = Q6_V_vmux_QVV(qu8_pred5, vu8_perm_lsb_2, vu8_perm_lsb_3);
    HVX_Vector vu8_msb_3 = Q6_V_vmux_QVV(qu8_pred6, vu8_perm_msb_3, vu8_perm_msb_4);
    HVX_Vector vu8_lsb_3 = Q6_V_vmux_QVV(qu8_pred7, vu8_perm_lsb_3, vu8_perm_lsb_4);

    vu8_shift04 = Q6_Vh_vasr_VhVh(vu8_lsb_0, vu8_shift);
    vu8_shift26 = Q6_Vh_vasr_VhR(vu8_shift04, 2);
    vu8_lsb_0   = Q6_V_vmux_QVV(qu8_oddeven, vu8_shift04, vu8_shift26);
    vu8_lsb_0   = Q6_V_vand_VV(vu8_lsb_0, vu8_const_3);

    vu8_shift04 = Q6_Vh_vasr_VhVh(vu8_lsb_1, vu8_shift);
    vu8_shift26 = Q6_Vh_vasr_VhR(vu8_shift04, 2);
    vu8_lsb_1   = Q6_V_vmux_QVV(qu8_oddeven, vu8_shift04, vu8_shift26);
    vu8_lsb_1   = Q6_V_vand_VV(vu8_lsb_1, vu8_const_3);

    vu8_shift04 = Q6_Vh_vasr_VhVh(vu8_lsb_2, vu8_shift);
    vu8_shift26 = Q6_Vh_vasr_VhR(vu8_shift04, 2);
    vu8_lsb_2   = Q6_V_vmux_QVV(qu8_oddeven, vu8_shift04, vu8_shift26);
    vu8_lsb_2   = Q6_V_vand_VV(vu8_lsb_2, vu8_const_3);

    vu8_shift04 = Q6_Vh_vasr_VhVh(vu8_lsb_3, vu8_shift);
    vu8_shift26 = Q6_Vh_vasr_VhR(vu8_shift04, 2);
    vu8_lsb_3   = Q6_V_vmux_QVV(qu8_oddeven, vu8_shift04, vu8_shift26);
    vu8_lsb_3   = Q6_V_vand_VV(vu8_lsb_3, vu8_const_3);

    wu16_out_perm0 = Q6_Wh_vmpa_WubRb(Q6_W_vcombine_VV(vu8_msb_0, vu8_lsb_0), const0401);
    wu16_out_perm1 = Q6_Wh_vmpa_WubRb(Q6_W_vcombine_VV(vu8_msb_1, vu8_lsb_1), const0401);
    wu16_out_perm2 = Q6_Wh_vmpa_WubRb(Q6_W_vcombine_VV(vu8_msb_2, vu8_lsb_2), const0401);
    wu16_out_perm3 = Q6_Wh_vmpa_WubRb(Q6_W_vcombine_VV(vu8_msb_3, vu8_lsb_3), const0401);

    wu16_dst0 = Q6_W_vshuff_VVR(Q6_V_hi_W(wu16_out_perm0), Q6_V_lo_W(wu16_out_perm0), -2);
    wu16_dst1 = Q6_W_vshuff_VVR(Q6_V_hi_W(wu16_out_perm1), Q6_V_lo_W(wu16_out_perm1), -2);
    wu16_dst2 = Q6_W_vshuff_VVR(Q6_V_hi_W(wu16_out_perm2), Q6_V_lo_W(wu16_out_perm2), -2);
    wu16_dst3 = Q6_W_vshuff_VVR(Q6_V_hi_W(wu16_out_perm3), Q6_V_lo_W(wu16_out_perm3), -2);
}

template <typename Dt, typename std::enable_if<std::is_same<Dt, DT_U16>::value>::type* = DT_NULL>
static DT_VOID MipiUnPackRow(const DT_U8 *src, Dt *dst, DT_S32 width)
{
    DT_U8 *dst_data    = (DT_U8 *)dst;
    DT_S32 width_algin = width & (-4 * AURA_HVLEN);

    HVX_Vector vu8_src0, vu8_src1, vu8_src2, vu8_src3, vu8_src4;
    HVX_VectorPair wu16_dst0, wu16_dst1, wu16_dst2, wu16_dst3;

    for (DT_S32 x = 0; x < width_algin; x += 4 * AURA_HVLEN)
    {
        vload(src, vu8_src0);
        vload(src + AURA_HVLEN, vu8_src1);
        vload(src + AURA_HVLEN * 2, vu8_src2);
        vload(src + AURA_HVLEN * 3, vu8_src3);
        vload(src + AURA_HVLEN * 4, vu8_src4);

        MipiUnPackRowCoreU16(vu8_src0, vu8_src1, vu8_src2, vu8_src3, vu8_src4, wu16_dst0, wu16_dst1, wu16_dst2, wu16_dst3);

        HVX_Vector vu16_dst0_lo, vu16_dst0_hi, vu16_dst1_lo, vu16_dst1_hi, vu16_dst2_lo, vu16_dst2_hi, vu16_dst3_lo, vu16_dst3_hi;
        vu16_dst0_lo = Q6_V_lo_W(wu16_dst0);
        vu16_dst0_hi = Q6_V_hi_W(wu16_dst0);
        vu16_dst1_lo = Q6_V_lo_W(wu16_dst1);
        vu16_dst1_hi = Q6_V_hi_W(wu16_dst1);
        vu16_dst2_lo = Q6_V_lo_W(wu16_dst2);
        vu16_dst2_hi = Q6_V_hi_W(wu16_dst2);
        vu16_dst3_lo = Q6_V_lo_W(wu16_dst3);
        vu16_dst3_hi = Q6_V_hi_W(wu16_dst3);

        vstore(dst_data                 , vu16_dst0_lo);
        vstore(dst_data + AURA_HVLEN    , vu16_dst0_hi);
        vstore(dst_data + AURA_HVLEN * 2, vu16_dst1_lo);
        vstore(dst_data + AURA_HVLEN * 3, vu16_dst1_hi);
        vstore(dst_data + AURA_HVLEN * 4, vu16_dst2_lo);
        vstore(dst_data + AURA_HVLEN * 5, vu16_dst2_hi);
        vstore(dst_data + AURA_HVLEN * 6, vu16_dst3_lo);
        vstore(dst_data + AURA_HVLEN * 7, vu16_dst3_hi);

        src += 5 * AURA_HVLEN;
        dst_data += (AURA_HVLEN << 3);
    }
    // remain
    if (width - width_algin)
    {
        DT_S32 length = ((width - width_algin) >> 2) * 5;
        dst_data = dst_data + ((width - width_algin) << 1) - (AURA_HVLEN << 3);

        vload(src + length - AURA_HVLEN * 5, vu8_src0);
        vload(src + length - AURA_HVLEN * 4, vu8_src1);
        vload(src + length - AURA_HVLEN * 3, vu8_src2);
        vload(src + length - AURA_HVLEN * 2, vu8_src3);
        vload(src + length - AURA_HVLEN, vu8_src4);

        MipiUnPackRowCoreU16(vu8_src0, vu8_src1, vu8_src2, vu8_src3, vu8_src4, wu16_dst0, wu16_dst1, wu16_dst2, wu16_dst3);

        HVX_Vector vu16_dst0_lo, vu16_dst0_hi, vu16_dst1_lo, vu16_dst1_hi, vu16_dst2_lo, vu16_dst2_hi, vu16_dst3_lo, vu16_dst3_hi;
        vu16_dst0_lo = Q6_V_lo_W(wu16_dst0);
        vu16_dst0_hi = Q6_V_hi_W(wu16_dst0);
        vu16_dst1_lo = Q6_V_lo_W(wu16_dst1);
        vu16_dst1_hi = Q6_V_hi_W(wu16_dst1);
        vu16_dst2_lo = Q6_V_lo_W(wu16_dst2);
        vu16_dst2_hi = Q6_V_hi_W(wu16_dst2);
        vu16_dst3_lo = Q6_V_lo_W(wu16_dst3);
        vu16_dst3_hi = Q6_V_hi_W(wu16_dst3);

        vstore(dst_data                 , vu16_dst0_lo);
        vstore(dst_data + AURA_HVLEN    , vu16_dst0_hi);
        vstore(dst_data + AURA_HVLEN * 2, vu16_dst1_lo);
        vstore(dst_data + AURA_HVLEN * 3, vu16_dst1_hi);
        vstore(dst_data + AURA_HVLEN * 4, vu16_dst2_lo);
        vstore(dst_data + AURA_HVLEN * 5, vu16_dst2_hi);
        vstore(dst_data + AURA_HVLEN * 6, vu16_dst3_lo);
        vstore(dst_data + AURA_HVLEN * 7, vu16_dst3_hi);
    }
}

template<typename Dt>
static Status MipiUnPackHvxImpl(const Mat &src, Mat &dst, DT_S32 start_row, DT_S32 end_row)
{
    DT_S32 iwidth = src.GetSizes().m_width;
    DT_S32 height = src.GetSizes().m_height;
    DT_S32 istride = src.GetStrides().m_width;
    DT_S32 owidth = dst.GetSizes().m_width;

    DT_U64 L2fetch_param = L2PfParam(istride, iwidth * ElemTypeSize(src.GetElemType()), 1, 0);
    for (DT_S32 y = start_row; y < end_row; y++)
    {
        if (y + 1 < height)
        {
            L2Fetch(reinterpret_cast<DT_U32>(src.Ptr<DT_U8>(y + 1)), L2fetch_param);
        }

        const DT_U8 *src_row = src.Ptr<DT_U8>(y);
        Dt *dst_row = dst.Ptr<Dt>(y);
        MipiUnPackRow<Dt>(src_row, dst_row, owidth);
    }

    return Status::OK;
}

MipiUnPackHvx::MipiUnPackHvx(Context *ctx, const OpTarget &target) : MipiUnPackImpl(ctx, target)
{}

Status MipiUnPackHvx::SetArgs(const Array *src, Array *dst)
{
    Status ret = Status::ERROR;

    if (MipiUnPackImpl::SetArgs(src, dst) != Status::OK)
    {
        AURA_ADD_ERROR_STRING(m_ctx, "MipiUnPackImpl::SetArgs failed");
        return ret;
    }

    if ((src->GetArrayType() != ArrayType::MAT) || (dst->GetArrayType() != ArrayType::MAT))
    {
        AURA_ADD_ERROR_STRING(m_ctx, "src dst must be mat type");
        return ret;
    }

    return Status::OK;
}

Status MipiUnPackHvx::Run()
{
    Status ret = Status::ERROR;

    const Mat *src = dynamic_cast<const Mat*>(m_src);
    Mat *dst       = dynamic_cast<Mat*>(m_dst);

    if ((DT_NULL == src) || (DT_NULL == dst))
    {
        AURA_ADD_ERROR_STRING(m_ctx, "src or dst is null");
        return ret;
    }

    WorkerPool *wp = m_ctx->GetWorkerPool();
    if (DT_NULL == wp)
    {
        AURA_ADD_ERROR_STRING(m_ctx, "GetWorkerpool failed");
        return ret;
    }

    DT_S32 height = src->GetSizes().m_height;

    switch (dst->GetElemType())
    {
        case ElemType::U8:
        {
            ret = wp->ParallelFor((DT_S32)0, height, MipiUnPackHvxImpl<DT_U8>, std::cref(*src), std::ref(*dst));
            if (ret != Status::OK)
            {
                AURA_ADD_ERROR_STRING(m_ctx, "MipiUnPackHvxImpl<DT_U8> failed");
            }
            break;
        }

        case ElemType::U16:
        {
            ret = wp->ParallelFor((DT_S32)0, height, MipiUnPackHvxImpl<DT_U16>, std::cref(*src), std::ref(*dst));
            if (ret != Status::OK)
            {
                AURA_ADD_ERROR_STRING(m_ctx, "MipiUnPackHvxImpl<DT_U16> failed");
            }
            break;
        }

        default:
        {
            AURA_ADD_ERROR_STRING(m_ctx, "elem type error");
            ret = Status::ERROR;
        }
    }

    AURA_RETURN(m_ctx, ret);
}

std::string MipiUnPackHvx::ToString() const
{
    return MipiUnPackImpl::ToString() + m_profiling_string;
}

Status MipiUnPackRpc(Context *ctx, HexagonRpcParam &rpc_param)
{
    Mat src;
    Mat dst;

    MipiUnPackInParam in_param(ctx, rpc_param);
    Status ret = in_param.Get(src, dst);
    if (ret != Status::OK)
    {
        AURA_ADD_ERROR_STRING(ctx, "Get failed");
        return Status::ERROR;
    }

    MipiUnPack mipi_unpack(ctx, OpTarget::Hvx());

    return OpCall(ctx, mipi_unpack, &src, &dst);
}

AURA_HEXAGON_RPC_FUNC_REGISTER(AURA_OPS_MISC_PACKAGE_NAME, AURA_OPS_MISC_MIPIUNPACK_OP_NAME, MipiUnPackRpc);

} // namespace aura